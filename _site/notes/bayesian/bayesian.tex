\input{./../note_style}

\title{\Huge \color{C1}  Bayesian Statistics}
\author{Ethan Levien}
\date{April 2022}

\begin{document}

\maketitle

\tableofcontents





\section{Parameters as random variables}
Let's revisit the very basic statistic model
\begin{equation}
Y \sim {\rm Bernoulli}(q).
\end{equation}
In our previous treatment of the statistical inference for this problem, we introduced the MLE which was obtained by maximizing the probability distribution $\Prob(Y|q)$. In classical statistics $q$ is a fixed number, NOT a random variable. Therefore, although we may not know the value of $q$ beforehand, it is assumed that there is some specific value of $q$ which is correct. The standard errors represent how much $q$ will vary between different replicates of the data (e.g. different subsamples of a population which are collected for a survey). There is a different way to think about uncertainty in parameters though: We can think of them as being random variables themselves. This has two advantages: First, it allows us to more easily quantify uncertainty in our parameters. Second, it allows to incorporate prior, sometimes subjective, knowledge about the parameters into our inference.

In some sense, treating parameters as random variables is a simple mater of exapanding our model, as the following example makes clear.
\begin{example}
Consider the model
\begin{align}
Y &\sim {\rm Bernoulli}(q)\\
q &\sim {\rm Beta}(2,1)
\end{align}
If we flip the coin twice, what the chance we get two heads in a row?
\end{example}


When we write down models in this way, with the probability distribution for the parameters specified as well as the other variables, we call the distribution of the parameters (a Beta distribution in the case) our priors.  Where do priors come from?

\begin{example}
Suppose that you are $95$ confident that a coin is fair, what are our priors?
\end{example}

\begin{exercise}
Suppose we conduct a survey of Dartmouth students asking the question: where you alive in 1995? We suspect that the answer will be no
\end{exercise}



\subsection{Priors for a regression model}


\begin{example}
Consider the model, with priors,
\begin{align}
Y &\sim {\rm Normal}(\alpha + \beta x,0.4)\\
\alpha &\sim {\rm Normal}(0,2)\\
\beta &\sim {\rm Normal}(1,2)
\end{align}
What is the chance that $Y>0.3$.
\end{exercise}
In the above examples, we fixed $\sigma$, but a it is reasonable to place priors on this as well. The question is: How do we do this in a way that ensures $\sigma>0$?

\begin{exercise} Consider the election example, suppose we know (e.g. from polling data that). What does this tell use about $\alpha$?
\end{exercise}


\section{Bayesian inference}

The question we know address is: How do we incorporate priors into our statistical inference? Bayes' theorem tell us exactly how to do this (in theory). In general, if $D$ is a our data and $\theta$ is our parameter(s), we can think of there being a joint distribution $\Prob(D,\theta)$, and hence
\begin{equation}
P(D|\theta)P(\theta) = P(\theta|D)\Prob(D)
\end{equation}
Rearraning this yields
\begin{equation}\label{eq:bayes}
P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)}
\end{equation}

\begin{exercise} Can you explain why Bayes theorem holds for both probability distributions and probability densities?
\end{exercise}


The distributions appearing in Equation \eqref{eq:bayes} have the following names and interpretations:
\begin{itemize}
\item $P(\theta|D)$ is the posterior.
\item $P(D|\theta)$ is the likelihood
\item $P(\theta)$ is the prior distribution
\item $P(D)$ is the evidence. It represents the chance we observe the data \emph{unconditional} on the parameters. This can be obtained by marginalizing over the priors.
\end{itemize}
While in classical statistics, the objective is to determine (estimate) a parameter $\theta$, in Bayesian statistics our objective is to compute the posteior distribution. Once we have this, we can obtain so-called {\dfn point estimates}, for example, by taking the average of $\theta$, most of the computational work that needs to be done surrounds the computation of the posterior thogh.


\subsection{MCMC}
In some cases, we can obtain analytical formula for the posterior distribution, but this is extremely rare. In reality, the best we can do is draw samples from the posterior distribution. The algorithms which achieve this are called Markov Chain Monte Carlo algorithms. The challange in Monte Carlo simulations is deal with the fact that $p(D)$ is unknown in Equation \eqref{eq:bayes}. If $p(D)$ was known, we would have a formula for $p(\theta|D)$, since the likelihood and the prior are both detemined by our model. The trick is that $p(D)$ doesn't depend on the parameters, and therefore, and therefore all distributions for which
\begin{equation}
  p(\theta|D) \propto U(\theta) = p(D|\theta)p(\theta)
\end{equation}
We want to generate samples in way that ensures the ratio between the frequancies of $\theta_1$ and $\theta_2$ are $U(\theta_1)/U(\theta_2)$. Let's say we have a sample $\theta_1$. Then we take a step  $\theta_2 = \theta + \Delta$. In order decide if we accept this new sample, we look at the ratio $U(\theta_1)/U(\theta_2)$. After many steps of this algorithm, we should have a set of samples of $\theta$ which is close to the actual.




\begin{example}
  Write a function which carries out Markov Chain Monte Carlo simulations
\end{example}


\subsection{Probabilistic programming in pymc3}

It turns out the way of doing MCMC simulations described above is not very practical for realy scienfitifc problems and more advanced methods require much more mathematics and are challanign to implement. Fortunately there are many esablished packages for performing these simulations. The one we will work with is called Pymc3. In Pymc3 we can define a model in a way similar to how we usually write them down.

\begin{Verbatim}
# now we build a model for the coin
# we start by simply defining a model using the Model() constructor
coin_flipping = Model()

# right now coin_flipping is just an "empty" model
# it has no variables or paramaters.
# model specifications in pymc3 are wrapped in a with-statement
# don't overthink this statement, basically within with is where we tell pymc what to do
with coin_flipping: #
    # first we define out priors
    # the model has one parameter p (the probability to get heads)
    q = Uniform("q", lower=0, upper=1)

    # now we tell pymc3 what the probability distribution of our data is
    # this is generally what we think of as a our "model" or likelihood
    y = Bernoulli("y", p=q, observed=flips)
\end{Verbatim}

Now that we've given pymc3 everything it needs to know about our statistical model.

NOTE: hen we specify distributions in pymc we do not use the ``np.random`` functions. Those generate samples from a random distribution, while here we are just telling pymc3 what the distributions of parameters and data are.


The next step is to sample from the Posterior distribution using Markov chain Monte Carlo simulations

\begin{Verbatim}
  # anything that we do with the model happens inside the with statement
  with coin_flipping:
    # this will generate samples from the posterior distribution
    # it may take a minute or so
    trace = sample(4000,cores =3)
\end{Verbatim}


The structure of the pymc inference code is:
\begin{enumerate}
\item  Tell pymc you are making a model by writing

\begin{Vertatim}
name_of_model = Model()
\end{Vertatim}


\item  In the indented code below a with statement tell pymc what you the distributions of your parameters and variables are. These can either be parameters or variables in our model we have data for.

This looks like:
\begin{Verbatim}
with name_of_model:
  # this defines out prior
  name_of_parameter = NameOfDistribution("name of variable",parameters)
  .
  .
  .
  # this defines our likelihood (our model)
  name_of_variable = NameOfDistribution("name of variable",parameters,observed = our data)
\end{Verbatim}

Generally the distribution functions that specify what distributions for pymc3 to use can take arrays for the parameters and observed data. For example, we can make the mean of the normal distribution a vector and the $i$th entry will be used as the mean for the $i$th entry of y. In particuar, for a regression model we can write:



\begin{Verbatim}
y = Normal("y",mu = a*x_data + b,sigma = sigma,observed = y_data)
\end{Verbatim}

\item In the indented code below a with statement tell pymc to generate samples from the posterior distribution. The pymc function for doing this is called sample.


\begin{Verbatim}
with name_of_model:
  trace = sample(number of samples)
\end{Verbatim}
\end{enumerate}}

Some things to remember:
\begin{itemize}
\item In general, don't do anything inside the with statement besides these things!
\item do things in this order
\item if you change something in your model or are making a new model do the first step agian
\end{itemize}

Trace is a python object which saves all the information about the posterior distribution. perhaps most importantly, trace stores a list of values of p. each number in this list is a random sample from the posterior distribution
\begin{Verbatim}
q_samples = trace["q"]
\end{Verbatim}
\section{Bayesian $p$-values}



\end{document}



%Sometimes we know the values of $\alpha$ and $\beta$ before seeing any data, for example, the ideal gas law. In this case, there is no need to carry out statistical inference. In the previous section, we discussed how statistical inference of the parameters $\alpha$, $\beta$ and $\sigma$ works, assuming no knowledge of these parameters. These is an intermediate between these two regimes: We might have a rough idea of what the parameters are from physical considerations or previous experiments. In this case, it is appropriate to incorporate this knowledge into out statistical inference. This can be done via \emph{priors}. In order to understand priors, let's work with the following exampe.
